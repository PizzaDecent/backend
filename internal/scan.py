import torch
import os
from PIL import Image
from ultralytics import YOLO
import numpy as np

# =========================
# –ö–æ–Ω—Ñ–∏–≥
# ========================
CONFIDENCE_THRESHOLD = 0.3  # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å YOLO –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
MIN_AREA_RATIO_DEFAULT = 0.005
MIN_AREA_RATIO_SCRATCH = 0.001
MAX_AREA_RATIO = 0.4
IGNORE_DAMAGE_PERCENT = 1.0
AVG_CONFIDENCE_MIN = 0.5

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É
BOX_CONFIDENCE_MIN_DEFAULT = 0.2
BOX_CONFIDENCE_MIN_SCRATCH = 0.2

# –ö–ª–∞—Å—Å—ã –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
CLASSES = {
    0: "scratch",
    1: "dent",
    2: "crack",
    3: "rust",
    4: "broken_part"
}

# –ü—É—Ç—å –∫ –≤–µ—Å–∞–º –º–æ–¥–µ–ª–∏ YOLO
base_dir = os.path.dirname(__file__)
weights_path = os.path.join(base_dir, "models/best.pt")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model = None

# =========================
# –£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ç–∏–ø—ã
# =========================
def convert_to_json_compatible(obj):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç numpy —Ç–∏–ø—ã –∏ –¥—Ä—É–≥–∏–µ –æ–±—ä–µ–∫—Ç—ã –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ç–∏–ø—ã"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_to_json_compatible(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_json_compatible(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_to_json_compatible(item) for item in obj)
    else:
        return obj

# =========================
# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# =========================
def load_model():
    global model
    if model is None:
        print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º YOLO –º–æ–¥–µ–ª—å...")
        if not os.path.exists(weights_path):
            print("‚ö†Ô∏è –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é YOLOv8")
            model = YOLO('yolov8n.pt')
        else:
            try:
                model = YOLO(weights_path)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {weights_path}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}")
                model = YOLO('yolov8n.pt')
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        model.to(device)
        print(f"üöÄ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    return model

# =========================
# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
# =========================
def predict_damage(img_path):
    yolo_model = load_model()
    if not os.path.exists(img_path):
        raise FileNotFoundError(f"–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {img_path}")

    img = Image.open(img_path).convert("RGB")
    img_w, img_h = img.size

    results = yolo_model.predict(
        source=img_path,
        conf=CONFIDENCE_THRESHOLD,
        iou=0.3,
        verbose=False,
        save=False,
        show=False
    )

    detections = []

    if results and len(results) > 0:
        result = results[0]
        if result.boxes is not None and len(result.boxes) > 0:
            boxes = result.boxes.xyxy.cpu().numpy()
            confidences = result.boxes.conf.cpu().numpy()
            classes = result.boxes.cls.cpu().numpy()

            for box, conf, cls in zip(boxes, confidences, classes):
                class_id = int(cls)
                damage_type = CLASSES.get(class_id, f"unknown_class_{class_id}")

                # –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π –ø–æ—Ä–æ–≥ –ø–ª–æ—â–∞–¥–∏ –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                min_area = MIN_AREA_RATIO_SCRATCH * img_w * img_h if damage_type == "scratch" else MIN_AREA_RATIO_DEFAULT * img_w * img_h
                box_conf_min = BOX_CONFIDENCE_MIN_SCRATCH if damage_type == "scratch" else BOX_CONFIDENCE_MIN_DEFAULT

                if float(conf) < box_conf_min:
                    continue

                x1, y1, x2, y2 = map(float, box)
                if x2 <= x1 or y2 <= y1:
                    continue

                area = (x2 - x1) * (y2 - y1)
                if not (min_area <= area <= MAX_AREA_RATIO * img_w * img_h):
                    continue

                detections.append({
                    "type": damage_type,
                    "confidence": round(float(conf) * 100, 2),
                    "box": [round(x1, 2), round(y1, 2), round(x2, 2), round(y2, 2)],
                    "area": round(float(area), 2)
                })

    return detections

# =========================
# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
# =========================
def predict_damage_with_metadata(img_path):
    detections = predict_damage(img_path)
    img = Image.open(img_path)
    img_w, img_h = img.size

    damage_stats = {}
    total_damage_area = 0.0
    confidences_list = []

    for d in detections:
        damage_type = str(d["type"])
        damage_stats[damage_type] = damage_stats.get(damage_type, 0) + 1
        total_damage_area += float(d["area"])
        confidences_list.append(float(d["confidence"]) / 100.0)

    image_area = float(img_w * img_h)
    damage_percentage = (total_damage_area / image_area) * 100 if image_area > 0 else 0.0
    avg_confidence = float(np.mean(confidences_list)) if confidences_list else 0.0

    # –õ–æ–≥–∏–∫–∞ severity
    if len(detections) == 0 or damage_percentage < IGNORE_DAMAGE_PERCENT or avg_confidence < AVG_CONFIDENCE_MIN:
        severity = "none"
    elif damage_percentage <= 5:
        severity = "low"
    elif damage_percentage <= 15:
        severity = "medium"
    else:
        severity = "high"

    result = {
        "image_info": {
            "path": str(img_path), 
            "width": int(img_w), 
            "height": int(img_h), 
            "area": int(image_area)
        },
        "damage_summary": {
            "total_detections": int(len(detections)),
            "damage_types": damage_stats,
            "total_damage_area": round(float(total_damage_area), 2),
            "damage_percentage": round(float(damage_percentage), 2),
            "average_confidence": round(float(avg_confidence * 100), 2),
            "severity": str(severity)
        },
        "detections": detections
    }
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Ç–∏–ø—ã
    return convert_to_json_compatible(result)

# =========================
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
# =========================
if __name__ == "__main__":
    test_images = ["test.jpg", "example.jpg", "sample.png"]
    for img_path in test_images:
        if os.path.exists(img_path):
            print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º: {img_path}")
            result = predict_damage_with_metadata(img_path)
            print(f"–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å: {result['damage_summary']['severity']}")
            print(f"–ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π: {result['damage_summary']['damage_percentage']}%")
            print(f"–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['damage_summary']['average_confidence']}%")
            print(f"–î–µ—Ç–µ–∫—Ü–∏–∏: {result['detections']}")